# -*- coding: utf-8 -*-
"""Neural Network Design With NLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/154W10hvul5r02D1AyG4BhI9SobOU4XAv
"""

pip install autokeras

!pip install googletrans==4.0.0-rc1

"""**Importing Dependencies**"""

import re
import os
import io
from contextlib import redirect_stdout
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, BatchNormalization, Dropout, Flatten, Conv2D, InputLayer
import autokeras as ak
from googletrans import Translator

"""**Defining Supported Languages**"""

SUPPORTED_LANGUAGES = {
    'en': 'English',
    'fr': 'French',
    'es': 'Spanish',
    'de': 'German',
    'hi': 'Hindi',
    'te': 'Telugu',
    'ja': 'Japanese',
    'zh-cn': 'Chinese (Simplified)',
    'ru': 'Russian'
}

"""**Parsing Model Description from User Input**"""

def parse_user_description(text):
    info = {
        "task_type": "text_classification",
        "total_layers": 3,
        "output_type": "binary",
        "num_classes": 2,
        "dropout_rate": 0.3,
        "rnn_type": "LSTM",
        "activation": "relu",
        "pooling_type": "max",
        "seq_len": 100,
        "vocab_size": 10000,
        "embed_dim": 128,
        "img_height": 64,
        "img_width": 64,
        "channels": 3,
        "num_features": 10,
        "signal_length": 128
    }

    text_lower = text.lower()

    tasks = {
        "text": "text_classification",
        "image": "image_classification",
        "regression": "regression",
        "time series": "time_series",
        "audio": "audio_classification"
    }
    for key in tasks:
        if key in text_lower:
            info["task_type"] = tasks[key]
            break

    match = re.search(r'(\d+)\s*layers?', text_lower)
    if match:
        info["total_layers"] = int(match.group(1))

    if "multiclass" in text_lower or "multi-class" in text_lower:
        info["output_type"] = "multiclass"
    if re.search(r'(\d+)\s*(output classes|classes|categories)', text_lower):
        num_classes_match = re.search(r'(\d+)\s*(output classes|classes|categories)', text_lower)
        if num_classes_match:
            info["output_type"] = "multiclass"
            info["num_classes"] = int(num_classes_match.group(1))
    elif "binary" in text_lower:
        info["output_type"] = "binary"
        info["num_classes"] = 2
    elif "regression" in text_lower:
        info["output_type"] = "regression"

    match = re.search(r'dropout\s*([\d\.]+)', text_lower)
    if match:
        info["dropout_rate"] = float(match.group(1))

    if "gru" in text_lower:
        info["rnn_type"] = "GRU"
    elif "lstm" in text_lower:
        info["rnn_type"] = "LSTM"

    for act in ["relu", "leakyrelu", "tanh"]:
        if act in text_lower:
            info["activation"] = act
            break

    for pool in ["max", "average"]:
        if pool in text_lower:
            info["pooling_type"] = pool
            break

    match_patterns = {
        "seq_len": r'sequence length\s*(\d+)',
        "vocab_size": r'vocab(ulary)? size\s*(\d+)',
        "embed_dim": r'embedding dimension\s*(\d+)',
        "img_height": r'image height\s*(\d+)',
        "img_width": r'image width\s*(\d+)',
        "channels": r'channels\s*(\d+)',
        "num_features": r'number of features\s*(\d+)',
        "signal_length": r'signal length\s*(\d+)'
    }

    for key, pattern in match_patterns.items():
        match = re.search(pattern, text_lower)
        if match:
            info[key] = int(match.group(1 if key != "vocab_size" else 2))

    return info

"""**Building Models for Different Task Types**"""

def build_text_classification_model(params):
    model = Sequential()
    model.add(Embedding(input_dim=params["vocab_size"], output_dim=params["embed_dim"], input_length=params["seq_len"]))
    model.add(LSTM(64) if params["rnn_type"] == "LSTM" else GRU(64))

    used_layers = 2
    remaining_layers = params["total_layers"] - used_layers
    units = 128

    for _ in range(remaining_layers // 3):
        model.add(Dense(units, activation=params["activation"]))
        model.add(BatchNormalization())
        model.add(Dropout(params["dropout_rate"]))
        units = max(16, units // 2)

    leftover = remaining_layers % 3
    if leftover >= 1:
        model.add(Dense(units, activation=params["activation"]))
    if leftover == 2:
        model.add(BatchNormalization())

    output_units = 1 if params["output_type"] == "binary" else params["num_classes"]
    activation = 'sigmoid' if params["output_type"] == "binary" else ('softmax' if params["output_type"] == "multiclass" else None)
    model.add(Dense(output_units, activation=activation))
    model.build(input_shape=(None, params["seq_len"]))
    return model

"""**All Tasks**"""

# Image Classification

def build_image_classification_model(params):
    model = Sequential()
    model.add(InputLayer(input_shape=(params["img_height"], params["img_width"], params["channels"])))

    filters = 64
    remaining_layers = params["total_layers"]
    while remaining_layers >= 3:
        model.add(Conv2D(filters, kernel_size=(3,3), activation='relu', padding='same'))
        model.add(BatchNormalization())
        model.add(Dropout(params["dropout_rate"]))
        filters = min(512, filters * 2)
        remaining_layers -= 3

    if remaining_layers >= 1:
        model.add(Conv2D(filters, kernel_size=(3,3), activation='relu', padding='same'))
        if remaining_layers == 2:
            model.add(BatchNormalization())

    model.add(Flatten())
    model.add(Dense(1 if params["output_type"] == "binary" else params["num_classes"],
                    activation='sigmoid' if params["output_type"] == "binary" else 'softmax'))
    model.build(input_shape=(None, params["img_height"], params["img_width"], params["channels"]))
    return model

# Regression

def build_regression_model(params):
    model = Sequential()
    model.add(InputLayer(input_shape=(params["num_features"],)))
    units = 128
    remaining = params["total_layers"] - 2

    for _ in range(remaining // 3):
        model.add(Dense(units, activation=params["activation"]))
        model.add(BatchNormalization())
        model.add(Dropout(params["dropout_rate"]))
        units = max(16, units // 2)

    if remaining % 3 >= 1:
        model.add(Dense(units, activation=params["activation"]))
    if remaining % 3 == 2:
        model.add(BatchNormalization())

    model.add(Dense(1))
    model.build(input_shape=(None, params["num_features"]))
    return model


# Time Series Data

def build_time_series_model(params):
    model = Sequential()
    model.add(InputLayer(input_shape=(params["seq_len"], params["num_features"])))
    units = 128
    remaining = params["total_layers"] - 1

    for _ in range(remaining // 3):
        model.add(LSTM(units, return_sequences=True))
        model.add(BatchNormalization())
        model.add(Dropout(params["dropout_rate"]))
        units = max(16, units // 2)

    if remaining % 3 >= 1:
        model.add(LSTM(units))
    if remaining % 3 == 2:
        model.add(BatchNormalization())

    if params["output_type"] == "regression":
        model.add(Dense(1))
    else:
        model.add(Dense(params["num_classes"], activation='softmax'))
    model.build(input_shape=(None, params["seq_len"], params["num_features"]))
    return model

# Audio Classification

def build_audio_classification_model(params):
    model = Sequential()
    model.add(InputLayer(input_shape=(params["signal_length"], params["channels"])))
    filters = 64
    remaining = params["total_layers"] - 1

    while remaining >= 3:
        model.add(Conv2D(filters, kernel_size=(3,1), activation='relu', padding='same'))
        model.add(BatchNormalization())
        model.add(Dropout(params["dropout_rate"]))
        filters = min(512, filters * 2)
        remaining -= 3

    if remaining >= 1:
        model.add(Conv2D(filters, kernel_size=(3,1), activation='relu', padding='same'))
        if remaining == 2:
            model.add(BatchNormalization())

    model.add(Flatten())
    model.add(Dense(1 if params["output_type"] == "binary" else params["num_classes"],
                    activation='sigmoid' if params["output_type"] == "binary" else 'softmax'))
    model.build(input_shape=(None, params["signal_length"], params["channels"]))
    return model

"""**Saving and Loading Model**"""

def save_and_load_model(model, save_path="model.keras"):
    if os.path.exists(save_path):
        os.remove(save_path)
    model.save(save_path)
    print(f"\nModel saved to '{save_path}'.")
    return load_model(save_path)

"""**Summary, Description, and Translation**"""

def get_model_summary_str(model):
    stream = io.StringIO()
    with redirect_stdout(stream):
        model.summary()
    return stream.getvalue()

def generate_model_description(params):
    description = f"This is a {params['task_type'].replace('_', ' ')} model with:\n"
    description += f"- {params['total_layers']} total layers\n"
    description += f"- {params['output_type']} output type\n"
    if params['output_type'] in ['binary', 'multiclass']:
        description += f"- {params['num_classes']} output classes\n"
    description += f"- Dropout rate: {params['dropout_rate']}\n"
    description += f"- Activation function: {params['activation']}\n"

    if params["task_type"] == "text_classification":
        description += f"- Using {params['rnn_type']} layers\n"
        description += f"- Sequence length: {params['seq_len']}\n"
        description += f"- Vocabulary size: {params['vocab_size']}\n"
        description += f"- Embedding dimension: {params['embed_dim']}\n"
    elif params["task_type"] == "image_classification":
        description += f"- Image dimensions: {params['img_height']}x{params['img_width']}x{params['channels']}\n"
    elif params["task_type"] == "time_series":
        description += f"- Sequence length: {params['seq_len']}\n"
        description += f"- Number of features: {params['num_features']}\n"
    elif params["task_type"] == "audio_classification":
        description += f"- Signal length: {params['signal_length']}\n"
        description += f"- Channels: {params['channels']}\n"
    elif params["task_type"] == "regression":
        description += f"- Number of features: {params['num_features']}\n"

    return description.strip()

def translate_text(text, dest_lang="en"):
    translator = Translator()
    try:
        return translator.translate(text, dest=dest_lang).text
    except Exception as e:
        print(f"Translation error: {e}")
        return text

"""**Main Function**"""

def main():
    print("Describe your model architecture in one sentence, e.g.:")
    print("Text classification with 5 layers, GRU, dropout 0.2, 3 output classes.")
    user_input = input("\nEnter model description: ")

    print("\nSupported languages:")
    for code, name in SUPPORTED_LANGUAGES.items():
        print(f"{code}: {name}")

    while True:
        lang = input("\nEnter 2-letter language code (e.g., 'hi' for Hindi, 'te' for Telugu) or press Enter for English: ").strip().lower()
        if not lang:
            lang = "en"
            break
        if lang in SUPPORTED_LANGUAGES:
            break
        print(f"Error: '{lang}' is not supported. Please choose from: {', '.join(SUPPORTED_LANGUAGES.keys())}")

    params = parse_user_description(user_input)
    print("\nParsed parameters:")
    for k, v in params.items():
        print(f"  {k}: {v}")

    task = params["task_type"]
    model_builders = {
        "text_classification": build_text_classification_model,
        "image_classification": build_image_classification_model,
        "regression": build_regression_model,
        "time_series": build_time_series_model,
        "audio_classification": build_audio_classification_model
    }
    model = model_builders.get(task, build_text_classification_model)(params)

    loaded_model = save_and_load_model(model)
    print("\nâœ… Generated model architecture:\n")
    summary_text = get_model_summary_str(loaded_model)
    print(summary_text)

    description = generate_model_description(params)
    print("\nModel Description (English):")
    print(description)

    if lang != "en":
        print(f"\nTranslating to {SUPPORTED_LANGUAGES[lang]}...")
        try:
            print(f"\nModel Summary ({SUPPORTED_LANGUAGES[lang]}):")
            print(translate_text(summary_text, dest_lang=lang))
            print(f"\nModel Description ({SUPPORTED_LANGUAGES[lang]}):")
            print(translate_text(description, dest_lang=lang))
        except Exception as e:
            print(f"Translation failed: {str(e)}\nShowing English version instead.")

if __name__ == "__main__":
    main()